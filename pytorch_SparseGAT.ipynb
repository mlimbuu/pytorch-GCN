{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHJ1wEcc+wxd6TgxLhr36E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlimbuu/pytorch-GCN/blob/main/pytorch_SparseGAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Environment"
      ],
      "metadata": {
        "id": "D8oT6YND6ykU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==2.3.0\n",
        "# !pip install networkx==3.3\n",
        "# !pip install scipy==1.13.0\n",
        "# !pip install numpy==1.26.4\n",
        "# !pip install jupyter==1.0.0"
      ],
      "metadata": {
        "id": "i79XZUAo6zt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "pQ1BJCYf-Ux2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading & Data Processing"
      ],
      "metadata": {
        "id": "JVxe6xUO64Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ],
      "metadata": {
        "id": "Yw0_Pb3r63tr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    # The classes must be sorted before encoding to enable static class encoding.\n",
        "    # In other words, make sure the first class always maps to index 0.\n",
        "    classes = sorted(list(set(labels)))\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def normalize_adj(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
        "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
        "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
        "\n",
        "def normalize_features(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def load_data(path=\"./data/data/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset), dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset), dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())), dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    # normalize features and adjacency matrix\n",
        "    features = normalize_features(features)\n",
        "    adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    adj = torch.FloatTensor(np.array(adj.todense()))\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test\n"
      ],
      "metadata": {
        "id": "ZMVICxzx-bss"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "adj, features, labels, idx_train, idx_val, idx_test = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQcDXh2T-h7a",
        "outputId": "a4ec6a9b-b5e1-4b99-9fd6-57b847bbb7ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cora dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "QwnbvxUM-AHg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etY88mhO-B5p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse GAT Layer"
      ],
      "metadata": {
        "id": "OgAYfC-J-C-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpecialSpmmFunction(torch.autograd.Function):\n",
        "    \"\"\"Special function for only sparse region backpropataion layer.\"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, indices, values, shape, b):\n",
        "        assert indices.requires_grad == False\n",
        "        a = torch.sparse_coo_tensor(indices, values, shape)\n",
        "        ctx.save_for_backward(a, b)\n",
        "        ctx.N = shape[0]\n",
        "        return torch.matmul(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        a, b = ctx.saved_tensors\n",
        "        grad_values = grad_b = None\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            grad_a_dense = grad_output.matmul(b.t())\n",
        "            edge_idx = a._indices()[0, :] * ctx.N + a._indices()[1, :]\n",
        "            grad_values = grad_a_dense.view(-1)[edge_idx]\n",
        "        if ctx.needs_input_grad[3]:\n",
        "            grad_b = a.t().matmul(grad_output)\n",
        "        return None, grad_values, None, grad_b\n",
        "\n",
        "class SpecialSpmm(nn.Module):\n",
        "    def forward(self, indices, values, shape, b):\n",
        "        return SpecialSpmmFunction.apply(indices, values, shape, b)"
      ],
      "metadata": {
        "id": "_cXtV0Bg_-J1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sparse_GraphAttentionLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Sparse version GAT layer, similar to https://arxiv.org/abs/1710.10903\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
        "        super(Sparse_GraphAttentionLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
        "        nn.init.xavier_normal_(self.W.data, gain=1.414)\n",
        "\n",
        "        self.a = nn.Parameter(torch.zeros(size=(1, 2*out_features)))\n",
        "        nn.init.xavier_normal_(self.a.data, gain=1.414)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "        self.special_spmm = SpecialSpmm()\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        dv = 'cuda' if input.is_cuda else 'cpu'\n",
        "\n",
        "        N = input.size()[0]\n",
        "        edge = adj.nonzero().t()\n",
        "\n",
        "        h = torch.mm(input, self.W)\n",
        "        # h: N x out\n",
        "        assert not torch.isnan(h).any()\n",
        "\n",
        "        # Self-attention on the nodes - Shared attention mechanism\n",
        "        edge_h = torch.cat((h[edge[0, :], :], h[edge[1, :], :]), dim=1).t()\n",
        "        # edge: 2*D x E\n",
        "\n",
        "        edge_e = torch.exp(-self.leakyrelu(self.a.mm(edge_h).squeeze()))\n",
        "        assert not torch.isnan(edge_e).any()\n",
        "        # edge_e: E\n",
        "\n",
        "        e_rowsum = self.special_spmm(edge, edge_e, torch.Size([N, N]), torch.ones(size=(N,1), device=dv))\n",
        "        # e_rowsum: N x 1\n",
        "\n",
        "        edge_e = self.dropout(edge_e)\n",
        "        # edge_e: E\n",
        "\n",
        "        h_prime = self.special_spmm(edge, edge_e, torch.Size([N, N]), h)\n",
        "        assert not torch.isnan(h_prime).any()\n",
        "        # h_prime: N x out\n",
        "\n",
        "        h_prime = h_prime.div(e_rowsum)\n",
        "        # h_prime: N x out\n",
        "        assert not torch.isnan(h_prime).any()\n",
        "\n",
        "        if self.concat:\n",
        "            # if this layer is not last layer,\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            # if this layer is last layer,\n",
        "            return h_prime\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n"
      ],
      "metadata": {
        "id": "MAxuq1YI-FHC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse GAT Model"
      ],
      "metadata": {
        "id": "s90CGeC1-FmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sparse_GAT(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
        "        \"\"\"Sparse version of GAT.\"\"\"\n",
        "        super(Sparse_GAT, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.attentions = [Sparse_GraphAttentionLayer(nfeat,\n",
        "                                                 nhid,\n",
        "                                                 dropout=dropout,\n",
        "                                                 alpha=alpha,\n",
        "                                                 concat=True) for _ in range(nheads)]\n",
        "        for i, attention in enumerate(self.attentions):\n",
        "            self.add_module('attention_{}'.format(i), attention)\n",
        "\n",
        "        self.out_att = Sparse_GraphAttentionLayer(nhid * nheads,\n",
        "                                             nclass,\n",
        "                                             dropout=dropout,\n",
        "                                             alpha=alpha,\n",
        "                                             concat=False)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.elu(self.out_att(x, adj))\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "hF_PDjLk-HZd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "zH9W7ZY_-Jcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & Test\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def train(epoch):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features, adj)\n",
        "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
        "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train.data.item()),\n",
        "          'acc_train: {:.4f}'.format(acc_train.data.item()),\n",
        "          'loss_val: {:.4f}'.format(loss_val.data.item()),\n",
        "          'acc_val: {:.4f}'.format(acc_val.data.item()),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    return loss_val, acc_val, output\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test.data.item()),\n",
        "          \"accuracy= {:.4f}\".format(acc_test.data.item()))\n"
      ],
      "metadata": {
        "id": "D8N_xeqDArIx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "seed = 72\n",
        "epochs = 1000\n",
        "lr = 0.005\n",
        "weight_decay = 5e-4\n",
        "hidden = 8\n",
        "nb_heads = 8\n",
        "dropout = 0.6\n",
        "alpha = 0.2\n",
        "patience = 100"
      ],
      "metadata": {
        "id": "v8ezqzk3-Ll4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = Sparse_GAT(nfeat=features.shape[1], nhid=hidden, nclass=int(labels.max()) + 1, dropout=dropout, nheads=nb_heads, alpha=alpha)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
      ],
      "metadata": {
        "id": "FTqEUvnd_qiF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "# Training model\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Training: {epoch}\")\n",
        "    val_loss, val_acc, out_features = train(epoch)\n",
        "    print(f\"loss_val:{val_loss}, val_acc:{val_acc}, out_features:{out_features}\")\n",
        "    # val_acc_list.append(val_acc.item())\n",
        "    # val_loss_list.append(loss_val.item())\n",
        "    val_loss_list.append(val_loss.item())\n",
        "    val_acc_list.append(val_acc.item())\n",
        "\n",
        "# Testing model\n",
        "test()"
      ],
      "metadata": {
        "id": "zg2gYo0pAgOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result Visualization"
      ],
      "metadata": {
        "id": "8ZTp2_-N-MYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Visualize earned feature representation"
      ],
      "metadata": {
        "id": "3UEI30CvA4Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize learned feature representation\n",
        "def visualize_learnedFeature_tSNE(labels, out_features, dataset):\n",
        "    color_map = {0: \"red\", 1: \"blue\", 2: \"green\",\n",
        "                           3: \"orange\", 4: \"yellow\", 5: \"pink\", 6: \"gray\"}\n",
        "\n",
        "    if dataset =='citeseer':\n",
        "        num_classes = 6\n",
        "    elif dataset == 'cora':\n",
        "        num_classes = 7\n",
        "    elif dataset =='pubmed':\n",
        "        num_classes = 3\n",
        "    node_labels = labels.cpu().numpy()\n",
        "    out_features = out_features.cpu().detach().numpy()\n",
        "    t_sne_X = TSNE(n_components=2, perplexity=30, method='barnes_hut').fit_transform(out_features)\n",
        "\n",
        "    plt.figure()\n",
        "    for class_id in range(num_classes):\n",
        "        plt.scatter(t_sne_X[node_labels == class_id, 0],\n",
        "                    t_sne_X[node_labels == class_id, 1], s=20,\n",
        "                    color=color_map[class_id],\n",
        "                    edgecolors='black', linewidths=0.15)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"t-SNE projection of the learned features for \"+dataset)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WWKstE5n-Oo9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Visulaize validation loss and accuracy"
      ],
      "metadata": {
        "id": "0j40yo9ZBDd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visulaize validation loss and accuracy\n",
        "def visualize_validation_performance(val_acc, val_loss):\n",
        "    f, ax = plt.subplots(1, 2, figsize=(13, 5.5))\n",
        "    ax[0].plot(val_loss, linewidth=2, color=\"red\")\n",
        "    ax[0].set_title(\"Validation loss\")\n",
        "    ax[0].set_ylabel(\"Cross Entropy Loss\")\n",
        "    ax[0].set_xlabel(\"Epoch\")\n",
        "    ax[0].grid()\n",
        "    ax[1].plot(val_acc, linewidth=2, color=\"red\")\n",
        "    ax[1].set_title(\"Validation accuracy\")\n",
        "    ax[1].set_ylabel(\"Acc\")\n",
        "    ax[1].set_xlabel(\"Epoch\")\n",
        "    ax[1].grid()"
      ],
      "metadata": {
        "id": "xYrWJ6EsBC2v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIxgL7ANBGU8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}